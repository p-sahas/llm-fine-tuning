{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "774ffaea",
   "metadata": {
    "id": "774ffaea"
   },
   "source": [
    "#### 00. Install dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480afda8",
   "metadata": {
    "executionInfo": {
     "elapsed": 22786,
     "status": "ok",
     "timestamp": 1768053545614,
     "user": {
      "displayName": "Sahas Induwara",
      "userId": "01111349774036367248"
     },
     "user_tz": -330
    },
    "id": "480afda8"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Core training libraries\n",
    "!pip install -q \\\n",
    "    transformers==4.44.2 \\\n",
    "    datasets==2.20.0 \\\n",
    "    tokenizers==0.19.1 \\\n",
    "    accelerate==0.34.2 \\\n",
    "    peft==0.12.0 \\\n",
    "    trl==0.9.6 \\\n",
    "    bitsandbytes==0.43.1 \\\n",
    "    evaluate==0.4.2\n",
    "\n",
    "# Utilities\n",
    "!pip install -q \\\n",
    "    numpy \\\n",
    "    pandas \\\n",
    "    scikit-learn \\\n",
    "    rich \\\n",
    "    pyyaml \\\n",
    "    python-dotenv \\\n",
    "    tqdm\n",
    "\n",
    "# Evaluation (requires pydantic v2)\n",
    "!pip install -q --upgrade pydantic\n",
    "!pip install -q google-genai rouge-score\n",
    "\n",
    "print(\" Installation complete!\")\n",
    "print(\" All dependencies compatible (pydantic v2 + google-genai)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432dec47",
   "metadata": {
    "id": "432dec47"
   },
   "source": [
    "## 1. Setting Up Environment Variables (Secrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3c9342",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13399,
     "status": "ok",
     "timestamp": 1768053641484,
     "user": {
      "displayName": "Sahas Induwara",
      "userId": "01111349774036367248"
     },
     "user_tz": -330
    },
    "id": "0a3c9342",
    "outputId": "56eaa263-4c05-4b5e-8a58-4b0db1b9c593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .env file created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create .env file with API key\n",
    "import os\n",
    "from google.colab import userdata\n",
    "# Write .env file\n",
    "# with open('.env', 'w') as f:\n",
    "#     # Add the secrets if needed\n",
    "#     f.write('GOOGLE_API_KEY=<api_key_here>\\n')\n",
    "#     f.write('HF_TOKEN=<api_key_here>\\n')\n",
    "\n",
    "# print(\" .env file created\")\n",
    "\n",
    "with open('.env', 'w') as f:\n",
    "    # Add the secrets if needed\n",
    "    f.write(f'GOOGLE_API_KEY={userdata.get('GOOGLE_API_KEY')}\\n')\n",
    "    f.write(f'HF_TOKEN={userdata.get('HF_TOKEN')}\\n')\n",
    "\n",
    "print(\" .env file created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab4c6cc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1768053643888,
     "user": {
      "displayName": "Sahas Induwara",
      "userId": "01111349774036367248"
     },
     "user_tz": -330
    },
    "id": "ab4c6cc2",
    "outputId": "b36d1b23-7a27-4274-9334-ea776d763cc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Keys in .env file:\n",
      "============================================================\n",
      "  GOOGLE_API_KEY = AIzaSyCkD_...\n",
      "  HF_TOKEN = hf_SyHkPTh...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify it's loaded\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Show only key names for security\n",
    "try:\n",
    "    with open('.env', 'r') as f:\n",
    "        print(\" Keys in .env file:\")\n",
    "        print(\"=\"*60)\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#'):\n",
    "                key = line.split('=')[0]\n",
    "                value_preview = line.split('=')[1][:10] + \"...\" if '=' in line else \"\"\n",
    "                print(f\"  {key} = {value_preview}\")\n",
    "        print(\"=\"*60)\n",
    "except FileNotFoundError:\n",
    "    print(\" .env file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6032fc",
   "metadata": {
    "id": "7b6032fc"
   },
   "source": [
    "## 2. Environment & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37cfb258",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1768053646605,
     "user": {
      "displayName": "Sahas Induwara",
      "userId": "01111349774036367248"
     },
     "user_tz": -330
    },
    "id": "37cfb258",
    "outputId": "4940933c-07d2-4306-f6de-ec9977afdcab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENVIRONMENT CHECK\n",
      "============================================================\n",
      "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "PyTorch version: 2.9.0+cpu\n",
      "CUDA available: False\n",
      " WARNING: CUDA not available. Training will be VERY slow on CPU.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ENVIRONMENT CHECK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Device capability: {torch.cuda.get_device_capability(0)}\")\n",
    "    print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\" WARNING: CUDA not available. Training will be VERY slow on CPU.\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f29630",
   "metadata": {
    "id": "91f29630"
   },
   "source": [
    "## 3. Seeds & Determinism\n",
    "\n",
    "Setting up random seeds for reproducibility. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f8a137",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1768053648486,
     "user": {
      "displayName": "Sahas Induwara",
      "userId": "01111349774036367248"
     },
     "user_tz": -330
    },
    "id": "37f8a137",
    "outputId": "ce39b882-aa24-4004-a760-514964bbf7fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Seeds set to 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Set environment variable for Python hash seed\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "# Set seeds\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    # Note: These settings may impact performance\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\" Seeds set to {SEED} for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ba553",
   "metadata": {
    "id": "492ba553"
   },
   "source": [
    "## 4. Hugging Face Login\n",
    "\n",
    "If you want to push your finetuned adapter to the Hugging Face Hub, uncomment and run the login line below.\n",
    "\n",
    "Hugging Face token with write permissions. Get one at: https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4840fa03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1768053681381,
     "user": {
      "displayName": "Sahas Induwara",
      "userId": "01111349774036367248"
     },
     "user_tz": -330
    },
    "id": "4840fa03",
    "outputId": "04d53676-4453-4c0f-dafd-b3cc4f4801e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "The token `Sahas AI` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "ℹ Hugging Face login skipped. Uncomment login() to push models to Hub.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n",
    "!hf auth login --token $HF_TOKEN\n",
    "\n",
    "print(\"ℹ Hugging Face login skipped. Uncomment login() to push models to Hub.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e475e96",
   "metadata": {
    "id": "9e475e96"
   },
   "source": [
    "## 5. Configuration (Single Source of Truth)\n",
    "\n",
    "All hyperparameters and settings in one place. **Edit here** to customize your training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca4ce9ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1768054710509,
     "user": {
      "displayName": "Sahas Induwara",
      "userId": "01111349774036367248"
     },
     "user_tz": -330
    },
    "id": "ca4ce9ed",
    "outputId": "c6e58012-8ef6-437d-f4c9-63b502d3a0cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION (COLAB FREE TIER)\n",
      "============================================================\n",
      "{'base_model': 'Qwen/Qwen2.5-1.5B-Instruct',\n",
      " 'bnb_4bit_compute_dtype': torch.float16,\n",
      " 'bnb_4bit_quant_type': 'nf4',\n",
      " 'bnb_4bit_use_double_quant': True,\n",
      " 'dataset_name': 'lavita/AlpaCare-MedInstruct-52k',\n",
      " 'dataset_split': 'train',\n",
      " 'dataset_subsample': 500,\n",
      " 'do_sample': True,\n",
      " 'eval_steps': 100,\n",
      " 'gradient_accumulation_steps': 64,\n",
      " 'hf_username': 'p-sahas',\n",
      " 'hub_model_name': 'sahas-medical-assistant',\n",
      " 'learning_rate': 2e-05,\n",
      " 'load_in_4bit': True,\n",
      " 'logging_steps': 10,\n",
      " 'lora_alpha': 32,\n",
      " 'lora_dropout': 0.05,\n",
      " 'lora_r': 16,\n",
      " 'lora_target_modules': ['q_proj',\n",
      "                         'k_proj',\n",
      "                         'v_proj',\n",
      "                         'o_proj',\n",
      "                         'gate_proj',\n",
      "                         'up_proj',\n",
      "                         'down_proj'],\n",
      " 'max_length': 512,\n",
      " 'max_new_tokens': 128,\n",
      " 'max_steps': 250,\n",
      " 'num_train_epochs': 1,\n",
      " 'output_dir': 'outputs/adapter',\n",
      " 'per_device_train_batch_size': 1,\n",
      " 'push_to_hub': False,\n",
      " 'save_steps': 200,\n",
      " 'save_total_limit': 2,\n",
      " 'temperature': 0.0,\n",
      " 'train_val_split': 0.9,\n",
      " 'warmup_ratio': 0.03}\n",
      "============================================================\n",
      "Compute dtype: torch.float16\n",
      "Using BF16: False\n",
      "Effective batch size: 64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "# Auto-detect compute dtype (BF16 requires compute capability >= 8.0)\n",
    "use_bf16 = torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n",
    "compute_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
    "\n",
    "CONFIG = {\n",
    "    # Model\n",
    "    \"base_model\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    # Alternative for tighter VRAM: \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "    # For GGUF export, prefer: \"meta-llama/Llama-3.2-3B-Instruct\" or Mistral models\n",
    "\n",
    "    # Dataset\n",
    "    \"dataset_name\": \"lavita/AlpaCare-MedInstruct-52k\",\n",
    "    \"dataset_split\": \"train\",\n",
    "    \"dataset_subsample\": 500,  # Colab-safe: 500 | Local: 1500\n",
    "    \"train_val_split\": 0.9,  # 90% train, 10% validation\n",
    "\n",
    "    # Tokenization\n",
    "    \"max_length\": 512,  # Colab: 512 | Local: 1024\n",
    "\n",
    "    # Training\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"max_steps\": 250,  # Colab: 250 | Local: 600\n",
    "    \"per_device_train_batch_size\": 1,  # Colab: 1 | Local: 2\n",
    "    \"gradient_accumulation_steps\": 64,  # Colab: 64 | Local: 32\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"warmup_ratio\": 0.03,\n",
    "    \"logging_steps\": 10,\n",
    "    \"save_steps\": 200,\n",
    "    \"eval_steps\": 100,\n",
    "    \"save_total_limit\": 2,\n",
    "\n",
    "    # LoRA\n",
    "    \"lora_r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"lora_target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "\n",
    "    # Quantization\n",
    "    \"load_in_4bit\": True,\n",
    "    \"bnb_4bit_compute_dtype\": compute_dtype,\n",
    "    \"bnb_4bit_quant_type\": \"nf4\",\n",
    "    \"bnb_4bit_use_double_quant\": True,\n",
    "\n",
    "    # Output\n",
    "    \"output_dir\": \"outputs/adapter\",\n",
    "    \"push_to_hub\": False,\n",
    "\n",
    "    # Generation\n",
    "    \"max_new_tokens\": 128,\n",
    "    \"temperature\": 0.0,  # Deterministic\n",
    "    \"do_sample\": True,\n",
    "\n",
    "    # HF credentials\n",
    "    'hf_username': 'p-sahas',\n",
    "    'hub_model_name': 'sahas-medical-assistant',\n",
    "}\n",
    "\n",
    "# Effective batch size\n",
    "effective_batch_size = CONFIG[\"per_device_train_batch_size\"] * CONFIG[\"gradient_accumulation_steps\"]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURATION (COLAB FREE TIER)\")\n",
    "print(\"=\"*60)\n",
    "pprint(CONFIG)\n",
    "print(\"=\"*60)\n",
    "print(f\"Compute dtype: {compute_dtype}\")\n",
    "print(f\"Using BF16: {use_bf16}\")\n",
    "print(f\"Effective batch size: {effective_batch_size}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BaTRiQAfP3o6",
   "metadata": {
    "id": "BaTRiQAfP3o6"
   },
   "source": [
    "#### FP16 vs BF16\n",
    "\n",
    "- BF -> Brain Float\n",
    "- Usually FP16 prioratize precision\n",
    "    - 5 exponent bits\n",
    "    - 10 mantissa bits\n",
    "- But BF prioratize dynamic range\n",
    "    - 8 exponent bits\n",
    "    - 7 mantiss bits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496429db",
   "metadata": {
    "id": "496429db"
   },
   "source": [
    "## 6. Dataset Loader (+ Fallback)\n",
    "\n",
    "Load the medical instruction dataset, map fields robustly, and create train/validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc7b123d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602,
     "referenced_widgets": [
      "5d28a91b82094fc08eed65ca93ba7e14",
      "f50ab5250da145b9bf560177d22ddf42",
      "efccff425e274441810be9d05497016b",
      "e30850e9567b49de8c79851b77e2b02f",
      "b9c7be37d6ef4f1390d61e3ab88ffb25",
      "b64675ab8ab5468087e50f75f08f2abd",
      "9e50a259f0c84e069a7688409335cca2",
      "2fbb139cbe8348e1b5b6aa76f4f98c5a",
      "b83d2abac1fb4e288b865eb1bfcad5c2",
      "cfc74eadc8cd4ddcb26c4eba5cc31482",
      "6390adb677554a2e8604f849652a1146",
      "71b0df20918d470489a3dd2b10ca234b",
      "b62c19f05f474ed2b9f4b261d11b0430",
      "a5608cdd0438432197832c7bcc823291",
      "f1500fe9b58e4233a730d8f8ade645fd",
      "b65aaa133fe0469c86b9bfa34f477e54",
      "7a017049f63b407194203e41f2407973",
      "bc67f963626345ea9412ce5caf367f61",
      "dd29a8f97f014895914a25b4941a26e2",
      "059b043ef44a438d92c61a977380cdb2",
      "e7a366e020a04ebcaf06f3de62c2436d",
      "4764ee7933e24cdd85bf3f10445d96e0"
     ]
    },
    "executionInfo": {
     "elapsed": 809,
     "status": "ok",
     "timestamp": 1768055579428,
     "user": {
      "displayName": "Sahas Induwara",
      "userId": "01111349774036367248"
     },
     "user_tz": -330
    },
    "id": "cc7b123d",
    "outputId": "93e1c910-3fdb-4dc9-ba09-c8cf96eae36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading dataset: lavita/AlpaCare-MedInstruct-52k...\n",
      " Loaded 500 examples from Hugging Face\n",
      "\n",
      " Dataset before cleaning: 500 examples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d28a91b82094fc08eed65ca93ba7e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b0df20918d470489a3dd2b10ca234b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset after cleaning: 500 examples\n",
      " Dropped 0 examples with missing data\n",
      "\n",
      " Train: 450 | Validation: 50\n",
      "\n",
      " Sample example:\n",
      "{'input': '<noinput>',\n",
      " 'instruction': 'Ask about the possible genetic risks your child might face '\n",
      "                \"related to Down Syndrome, given that you're a 40years old \"\n",
      "                'pregnant woman.',\n",
      " 'output': 'As a 40-year-old pregnant woman, your age does increase the risk '\n",
      "           \"of having a baby with Down syndrome. However, it's important to \"\n",
      "           'note that the majority of babies born to women in their 40s are '\n",
      "           'still healthy and do not have Down syndrome. \\n'\n",
      "           '\\n'\n",
      "           'The risk of having a baby with Down syndrome at the age of 40 is '\n",
      "           'approximately 1 in 100. This means that out of 100 pregnancies at '\n",
      "           'this age, around 1 will be affected by Down syndrome. \\n'\n",
      "           '\\n'\n",
      "           'To get more accurate information about your individual risk, you '\n",
      "           'may consider undergoing prenatal screening or diagnostic tests. '\n",
      "           'These tests can provide more specific information regarding the '\n",
      "           \"chance of your baby having Down syndrome. It's advisable to \"\n",
      "           'consult with your healthcare provider who can guide you through '\n",
      "           'the appropriate testing options based on your personal medical '\n",
      "           'history and preferences.'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import json\n",
    "\n",
    "def load_medical_dataset(dataset_name, split, subsample, seed=42):\n",
    "    \"\"\"Load dataset with robust field mapping and fallback.\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Try loading from Hugging Face\n",
    "        print(f\" Loading dataset: {dataset_name}...\")\n",
    "        dataset = load_dataset(dataset_name, split=split)\n",
    "        dataset = dataset.shuffle(seed=seed).select(range(min(subsample, len(dataset))))\n",
    "        print(f\" Loaded {len(dataset)} examples from Hugging Face\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to load from Hugging Face: {e}\")\n",
    "        print(\" Creating synthetic fallback dataset...\")\n",
    "\n",
    "        # Create synthetic medical instruction data\n",
    "        synthetic_data = []\n",
    "        templates = [\n",
    "            {\n",
    "                \"instruction\": \"Explain the following medical term in simple language.\",\n",
    "                \"input\": \"Hypertension\",\n",
    "                \"output\": \"Hypertension, commonly known as high blood pressure, is a condition where the force of blood against artery walls is consistently too high. This can lead to serious health complications if left untreated.\"\n",
    "            },\n",
    "            {\n",
    "                \"instruction\": \"What are the common symptoms of the following condition?\",\n",
    "                \"input\": \"Type 2 Diabetes\",\n",
    "                \"output\": \"Common symptoms of Type 2 Diabetes include increased thirst, frequent urination, increased hunger, fatigue, blurred vision, slow-healing sores, and frequent infections.\"\n",
    "            },\n",
    "            {\n",
    "                \"instruction\": \"Provide general advice for managing the following health issue.\",\n",
    "                \"input\": \"Chronic back pain\",\n",
    "                \"output\": \"Managing chronic back pain typically involves: maintaining good posture, regular low-impact exercise like swimming or walking, maintaining a healthy weight, using proper lifting techniques, and consulting with healthcare providers for appropriate treatment options.\"\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        # Duplicate to reach ~120 examples\n",
    "        for i in range(40):\n",
    "            for template in templates:\n",
    "                synthetic_data.append(template)\n",
    "\n",
    "        # Save to temporary JSONL\n",
    "        with open(\"/tmp/synthetic_medical.jsonl\", \"w\") as f:\n",
    "            for item in synthetic_data[:subsample]:\n",
    "                f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "        dataset = load_dataset(\"json\", data_files=\"/tmp/synthetic_medical.jsonl\", split=\"train\")\n",
    "        print(f\" Created synthetic dataset with {len(dataset)} examples\")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def map_dataset_fields(example):\n",
    "    \"\"\"Robustly map dataset fields to instruction/input/output schema.\"\"\"\n",
    "\n",
    "    # Try to find instruction\n",
    "    instruction = None\n",
    "    for key in [\"instruction\", \"question\", \"prompt\", \"task\"]:\n",
    "        if key in example and example[key]:\n",
    "            instruction = str(example[key]).strip()\n",
    "            break\n",
    "\n",
    "    # Try to find input (optional)\n",
    "    input_text = \"\"\n",
    "    for key in [\"input\", \"context\", \"passage\", \"history\"]:\n",
    "        if key in example and example[key]:\n",
    "            input_text = str(example[key]).strip()\n",
    "            break\n",
    "\n",
    "    # Try to find output/target\n",
    "    output = None\n",
    "    for key in [\"output\", \"response\", \"answer\", \"target\", \"completion\"]:\n",
    "        if key in example and example[key]:\n",
    "            output = str(example[key]).strip()\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": input_text,\n",
    "        \"output\": output\n",
    "    }\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_medical_dataset(\n",
    "    CONFIG[\"dataset_name\"],\n",
    "    CONFIG[\"dataset_split\"],\n",
    "    CONFIG[\"dataset_subsample\"],\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "print(f\"\\n Dataset before cleaning: {len(dataset)} examples\")\n",
    "\n",
    "# Map fields\n",
    "dataset = dataset.map(map_dataset_fields)\n",
    "\n",
    "# Drop rows with missing instruction or output\n",
    "dataset = dataset.filter(lambda x: x[\"instruction\"] is not None and x[\"output\"] is not None)\n",
    "\n",
    "print(f\" Dataset after cleaning: {len(dataset)} examples\")\n",
    "print(f\" Dropped {CONFIG['dataset_subsample'] - len(dataset)} examples with missing data\\n\")\n",
    "\n",
    "# Split into train/validation\n",
    "split_dataset = dataset.train_test_split(\n",
    "    train_size=CONFIG[\"train_val_split\"],\n",
    "    seed=SEED\n",
    ")\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "val_dataset = split_dataset[\"test\"]\n",
    "\n",
    "print(f\" Train: {len(train_dataset)} | Validation: {len(val_dataset)}\")\n",
    "print(\"\\n Sample example:\")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LRa9Tn5AU10B",
   "metadata": {
    "id": "LRa9Tn5AU10B"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert first 50 samples to dataframe\n",
    "df_preview = pd.DataFrame(train_dataset[:50])\n",
    "\n",
    "# Display with formatting\n",
    "pd.set_option('display.max_colwidth', 100)  # Limit column width for readability\n",
    "print(f\" Displaying first 50 samples out of {len(dataset)} total examples\\n\")\n",
    "df_preview"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sahas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "059b043ef44a438d92c61a977380cdb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2fbb139cbe8348e1b5b6aa76f4f98c5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4764ee7933e24cdd85bf3f10445d96e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d28a91b82094fc08eed65ca93ba7e14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f50ab5250da145b9bf560177d22ddf42",
       "IPY_MODEL_efccff425e274441810be9d05497016b",
       "IPY_MODEL_e30850e9567b49de8c79851b77e2b02f"
      ],
      "layout": "IPY_MODEL_b9c7be37d6ef4f1390d61e3ab88ffb25"
     }
    },
    "6390adb677554a2e8604f849652a1146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71b0df20918d470489a3dd2b10ca234b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b62c19f05f474ed2b9f4b261d11b0430",
       "IPY_MODEL_a5608cdd0438432197832c7bcc823291",
       "IPY_MODEL_f1500fe9b58e4233a730d8f8ade645fd"
      ],
      "layout": "IPY_MODEL_b65aaa133fe0469c86b9bfa34f477e54"
     }
    },
    "7a017049f63b407194203e41f2407973": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e50a259f0c84e069a7688409335cca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5608cdd0438432197832c7bcc823291": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd29a8f97f014895914a25b4941a26e2",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_059b043ef44a438d92c61a977380cdb2",
      "value": 500
     }
    },
    "b62c19f05f474ed2b9f4b261d11b0430": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a017049f63b407194203e41f2407973",
      "placeholder": "​",
      "style": "IPY_MODEL_bc67f963626345ea9412ce5caf367f61",
      "value": "Filter: 100%"
     }
    },
    "b64675ab8ab5468087e50f75f08f2abd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b65aaa133fe0469c86b9bfa34f477e54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b83d2abac1fb4e288b865eb1bfcad5c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b9c7be37d6ef4f1390d61e3ab88ffb25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc67f963626345ea9412ce5caf367f61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfc74eadc8cd4ddcb26c4eba5cc31482": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd29a8f97f014895914a25b4941a26e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e30850e9567b49de8c79851b77e2b02f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cfc74eadc8cd4ddcb26c4eba5cc31482",
      "placeholder": "​",
      "style": "IPY_MODEL_6390adb677554a2e8604f849652a1146",
      "value": " 500/500 [00:00&lt;00:00, 2600.13 examples/s]"
     }
    },
    "e7a366e020a04ebcaf06f3de62c2436d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efccff425e274441810be9d05497016b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fbb139cbe8348e1b5b6aa76f4f98c5a",
      "max": 500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b83d2abac1fb4e288b865eb1bfcad5c2",
      "value": 500
     }
    },
    "f1500fe9b58e4233a730d8f8ade645fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7a366e020a04ebcaf06f3de62c2436d",
      "placeholder": "​",
      "style": "IPY_MODEL_4764ee7933e24cdd85bf3f10445d96e0",
      "value": " 500/500 [00:00&lt;00:00, 13883.83 examples/s]"
     }
    },
    "f50ab5250da145b9bf560177d22ddf42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b64675ab8ab5468087e50f75f08f2abd",
      "placeholder": "​",
      "style": "IPY_MODEL_9e50a259f0c84e069a7688409335cca2",
      "value": "Map: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
